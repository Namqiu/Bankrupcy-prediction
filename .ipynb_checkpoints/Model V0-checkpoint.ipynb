{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.read_csv('Merged_1985-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>LPERMNO</th>\n",
       "      <th>fyear</th>\n",
       "      <th>ni</th>\n",
       "      <th>dv</th>\n",
       "      <th>fincf</th>\n",
       "      <th>ivncf</th>\n",
       "      <th>oancf</th>\n",
       "      <th>ch</th>\n",
       "      <th>gp</th>\n",
       "      <th>xint</th>\n",
       "      <th>lct</th>\n",
       "      <th>dltt</th>\n",
       "      <th>xrent</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>che</th>\n",
       "      <th>cstkcv</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>bankrupt</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMFD.</td>\n",
       "      <td>A &amp; M FOOD SERVICES INC</td>\n",
       "      <td>10015</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2.576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.688</td>\n",
       "      <td>40.268</td>\n",
       "      <td>1.726</td>\n",
       "      <td>13.922</td>\n",
       "      <td>11.908</td>\n",
       "      <td>1.263</td>\n",
       "      <td>10.125</td>\n",
       "      <td>2.787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANTQ</td>\n",
       "      <td>A.A. IMPORTING CO INC</td>\n",
       "      <td>10031</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.330</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2.643</td>\n",
       "      <td>4.682</td>\n",
       "      <td>1.211</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANTQ</td>\n",
       "      <td>A.A. IMPORTING CO INC</td>\n",
       "      <td>10031</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241</td>\n",
       "      <td>17.189</td>\n",
       "      <td>0.448</td>\n",
       "      <td>3.378</td>\n",
       "      <td>3.750</td>\n",
       "      <td>2.267</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANTQ</td>\n",
       "      <td>A.A. IMPORTING CO INC</td>\n",
       "      <td>10031</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.744</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>0.475</td>\n",
       "      <td>13.589</td>\n",
       "      <td>0.502</td>\n",
       "      <td>2.921</td>\n",
       "      <td>5.478</td>\n",
       "      <td>2.337</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANTQ</td>\n",
       "      <td>A.A. IMPORTING CO INC</td>\n",
       "      <td>10031</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>-7.838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.223</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-2.100</td>\n",
       "      <td>0.302</td>\n",
       "      <td>11.088</td>\n",
       "      <td>0.727</td>\n",
       "      <td>16.370</td>\n",
       "      <td>0.104</td>\n",
       "      <td>2.944</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tic                     conm  LPERMNO   fyear     ni   dv  fincf  ivncf  \\\n",
       "0  AMFD.  A & M FOOD SERVICES INC    10015  1985.0  2.576  0.0    NaN    NaN   \n",
       "1   ANTQ    A.A. IMPORTING CO INC    10031  1985.0  0.236  0.0    NaN    NaN   \n",
       "2   ANTQ    A.A. IMPORTING CO INC    10031  1986.0  0.793  0.0    NaN    NaN   \n",
       "3   ANTQ    A.A. IMPORTING CO INC    10031  1987.0  0.186  0.0  1.744 -0.523   \n",
       "4   ANTQ    A.A. IMPORTING CO INC    10031  1988.0 -7.838  0.0  2.223 -0.296   \n",
       "\n",
       "   oancf     ch      gp   xint     lct    dltt  xrent  prcc_f    che  cstkcv  \\\n",
       "0    NaN  1.688  40.268  1.726  13.922  11.908  1.263  10.125  2.787     NaN   \n",
       "1    NaN  0.005  10.330  0.273   2.643   4.682  1.211   4.500  0.005     0.1   \n",
       "2    NaN  0.241  17.189  0.448   3.378   3.750  2.267   4.500  0.241     0.1   \n",
       "3 -0.987  0.475  13.589  0.502   2.921   5.478  2.337   2.750  0.475     0.1   \n",
       "4 -2.100  0.302  11.088  0.727  16.370   0.104  2.944   1.750  0.302     0.1   \n",
       "\n",
       "   PERMNO  bankrupt  year  quarter  \n",
       "0   10015       0.0   NaN      NaN  \n",
       "1   10031       0.0   NaN      NaN  \n",
       "2   10031       0.0   NaN      NaN  \n",
       "3   10031       0.0   NaN      NaN  \n",
       "4   10031       0.0   NaN      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag one year ahead #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f08b3ba2db01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# cmcm = lag(cm[cm['tic'] == 'TSLA'],2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mcmcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mcmcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f08b3ba2db01>\u001b[0m in \u001b[0;36mlag\u001b[0;34m(data, year_lag)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# identify the real bankrupt row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bankrupt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fyear_lag1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bankrupt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4723\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4725\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4726\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_internal_get_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_internal_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;34m\"\"\" return a dense type view \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# year_lag = lag for x years \n",
    "# e.g. a row with 2018 data -- year_lag = 2 -- (2018) 2017 2016\n",
    "\n",
    "def lag(data, year_lag = 2):\n",
    "\n",
    "    # change the fyear to ascend within every LPERMNO\n",
    "    data.sort_values(['LPERMNO', 'fyear'], ascending = [True, True], inplace = True)\n",
    "\n",
    "    # remove irrelevant columns first\n",
    "    df = data.drop(columns = ['PERMNO','bankrupt','quarter','year'])\n",
    "    \n",
    "    # get the columns\n",
    "    columns = df.columns\n",
    "    col_to_lag = columns[3:]\n",
    "\n",
    "    # run the loops to create lag columns to the number of lagged year\n",
    "    for lag in range(1, year_lag+1):\n",
    "        for colname in col_to_lag:\n",
    "            df[f'{colname}'+ '_lag' + f'{lag}'] = df[f'{colname}'].shift((lag-1))\n",
    "\n",
    "    # add back the bankrupt info\n",
    "    df['bankrupt'] = data['bankrupt']\n",
    "    df['year'] = data['year']\n",
    "    df['quarter'] = data['quarter']\n",
    "\n",
    "    # keep the new lagged columns and remove the original one\n",
    "    df.drop(col_to_lag, axis=1, inplace = True)\n",
    "\n",
    "    # drop the last row of each LPERMNO after lagging one year\n",
    "    df = df.groupby(['LPERMNO']).apply(lambda x: x.iloc[1:])\n",
    "    df = df.set_index('LPERMNO').reset_index()    \n",
    "    \n",
    "    # identify the real bankrupt row\n",
    "    for i in range(len(df)):\n",
    "        if (df['bankrupt'][i] == 1) & (df['year'][i] - df['fyear_lag1'][i] == 1):\n",
    "            df['bankrupt'][i] = 1\n",
    "        else:\n",
    "            df['bankrupt'][i] = 0\n",
    "\n",
    "    df['predict_year'] = df['fyear_lag1']+1\n",
    "\n",
    "    return df\n",
    "\n",
    "# cmcm = lag(cm[cm['tic'] == 'TSLA'],2)\n",
    "cmcm = lag(cm ,2)\n",
    "cmcm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "cmcm['bankrupt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmcm[cmcm['predict_year'] != 2020]['bankrupt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(data, y_label, k = 5, seed = 1):\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    X = data.loc[:, data.columns != y_label]\n",
    "    y = data[y_label]\n",
    "\n",
    "    sm = SMOTE(sampling_strategy = 'auto', k_neighbors = k, random_state = seed)\n",
    "\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    \n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "def undersampling(data, y_label, n = 3):\n",
    "\n",
    "    from imblearn.under_sampling import NearMiss\n",
    "\n",
    "    X = data.loc[:, data.columns != y_label]\n",
    "    y = data[y_label]\n",
    "\n",
    "    nm = NearMiss(sampling_strategy = 'auto')\n",
    "\n",
    "    X_res, y_res = nm.fit_resample(X, y)\n",
    "    \n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cross_validation(model,X,y,K):\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    kf = KFold(K,shuffle=True)\n",
    "    folds = list(kf.split(X))\n",
    "    train_performance = np.empty(K)\n",
    "    validation_performance = np.empty(K)\n",
    "    \n",
    "    for idx in range(K):\n",
    "        train,validation = folds[idx] # this give us the indexes of train and validation datapoints in current fold\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        model.fit(X_train,y_train)\n",
    "        train_accuracy = np.average(model.predict(X_train) == y_train)\n",
    "        X_validation = X[validation]\n",
    "        y_validation = y[validation]\n",
    "        validation_accuracy = np.average(model.predict(X_validation)==y_validation)\n",
    "        train_performance[idx] = train_accuracy\n",
    "        validation_performance[idx] = validation_accuracy\n",
    "    return train_performance,validation_performance\n",
    "\n",
    "cross_validation = {}\n",
    "kfolds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso = Lasso()\n",
    "\n",
    "# parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1e-1, 1 , 2, 3, 5, 10, 20]}\n",
    "# # once we know best range of alpha we can scope it down\n",
    "\n",
    "# lasso_regressor = GridSearchCV(lass, parameters, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "\n",
    "# lasso_regressor.fit(X,y)\n",
    "\n",
    "# lasso_regressor.best_params_\n",
    "# lasso_regressor.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan 1: Drop all the missing values. Change all the 0 value to a small number. Only 99283 rows left, abount 50% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = cmcm.dropna(subset= cmcm.columns[4:33])\n",
    "cm1[cm1['predict_year'] != 2020]['bankrupt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1_sm = cm1.drop(['LPERMNO','tic','conm', 'year', 'quarter','fyear_lag1','fyear_lag2'],axis=1)\n",
    "print(cm1_sm['bankrupt'].value_counts())\n",
    "\n",
    "x, y = oversampling(cm1_sm, 'bankrupt')\n",
    "x = x.drop(['predict_year'],axis = 1)\n",
    "cm1_smote = pd.merge(x, y, left_index = True, right_index = True)\n",
    "cm1_smote['bankrupt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic model without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_model_without_scaling(x,y,train_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = train_size)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = Logistic_model_without_scaling(x,y,0.3)\n",
    "model = LogisticRegression()\n",
    "train_performance,validation_performance = model_cross_validation(model,x_train,y_train,kfolds)\n",
    "cross_validation['Logistic model without scaling'] = (np.mean(train_performance), np.mean(validation_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic model with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_model_with_scaling(x,y,train_size):\n",
    "    scaler = StandardScaler()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = train_size)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = Logistic_model_with_scaling(x,y,0.3)\n",
    "model = LogisticRegression()\n",
    "train_performance,validation_performance = model_cross_validation(model,x_train,y_train,kfolds)\n",
    "cross_validation['Logistic model with scaling'] = (np.mean(train_performance), np.mean(validation_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic model using categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_model_using_categorical_vraibles(x,y,train_size):\n",
    "    # I use the data without scaling because it performs better than with scaling.\n",
    "    # dv, dltt, cstkcv can not be divided into 10 different groups so I will deal with others first.\n",
    "    x1 = x.copy().drop(['dv_lag1','dv_lag2','dltt_lag1','dltt_lag2','cstkcv_lag1','cstkcv_lag2'],axis=1)\n",
    "    \n",
    "    # Categorical from 1 to 10 (so in the future maybe we can set NA and inf to 0)\n",
    "    for col in x1.columns:\n",
    "        x1[col] = pd.qcut(x1[col],10,labels=np.arange(1,11))\n",
    "    \n",
    "    x2 = x.copy()[['dv_lag1','dv_lag2','dltt_lag1','dltt_lag2','cstkcv_lag1','cstkcv_lag2']]\n",
    "    # They can only be divided into 3 categories.\n",
    "    for col in x2.columns:\n",
    "        x2[col] = pd.qcut(x2[col],3,labels=np.arange(1,4))\n",
    "        \n",
    "    x = x2.join(x1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = train_size)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = Logistic_model_using_categorical_vraibles(x,y,0.3)\n",
    "model = LogisticRegression()\n",
    "train_performance,validation_performance = model_cross_validation(model,x_train,y_train,kfolds)\n",
    "cross_validation['Logistic model using categorical variables'] = (np.mean(train_performance), np.mean(validation_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_results = {k: v for k, v in sorted(cross_validation.items(), key=lambda item: item[1], reverse=True)}\n",
    "best_model = list(cross_validation_results.keys())[0] \n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = Logistic_model_using_categorical_vraibles(x,y,0.3)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,threshold = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Bankrupt Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas_profiling\n",
    "# profile = pandas_profiling.ProfileReport(cm1)\n",
    "# profile.to_file(outputfile = 'Profile.html')\n",
    "# profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
